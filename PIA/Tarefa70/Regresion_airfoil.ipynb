{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torchmetrics import MeanSquaredError, MeanAbsoluteError, R2Score\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizamos el contenido del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Angle of attack</th>\n",
       "      <th>Chord length</th>\n",
       "      <th>Free-stream velocity</th>\n",
       "      <th>Suction side displacement thickness</th>\n",
       "      <th>Pressure level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>126.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>125.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>125.951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>127.591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>127.461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>2500</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.1016</td>\n",
       "      <td>39.6</td>\n",
       "      <td>0.052849</td>\n",
       "      <td>110.264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>3150</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.1016</td>\n",
       "      <td>39.6</td>\n",
       "      <td>0.052849</td>\n",
       "      <td>109.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>4000</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.1016</td>\n",
       "      <td>39.6</td>\n",
       "      <td>0.052849</td>\n",
       "      <td>106.604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>5000</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.1016</td>\n",
       "      <td>39.6</td>\n",
       "      <td>0.052849</td>\n",
       "      <td>106.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>6300</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.1016</td>\n",
       "      <td>39.6</td>\n",
       "      <td>0.052849</td>\n",
       "      <td>104.204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1503 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Frequency  Angle of attack  Chord length  Free-stream velocity  \\\n",
       "0           800              0.0        0.3048                  71.3   \n",
       "1          1000              0.0        0.3048                  71.3   \n",
       "2          1250              0.0        0.3048                  71.3   \n",
       "3          1600              0.0        0.3048                  71.3   \n",
       "4          2000              0.0        0.3048                  71.3   \n",
       "...         ...              ...           ...                   ...   \n",
       "1498       2500             15.6        0.1016                  39.6   \n",
       "1499       3150             15.6        0.1016                  39.6   \n",
       "1500       4000             15.6        0.1016                  39.6   \n",
       "1501       5000             15.6        0.1016                  39.6   \n",
       "1502       6300             15.6        0.1016                  39.6   \n",
       "\n",
       "      Suction side displacement thickness  Pressure level  \n",
       "0                                0.002663         126.201  \n",
       "1                                0.002663         125.201  \n",
       "2                                0.002663         125.951  \n",
       "3                                0.002663         127.591  \n",
       "4                                0.002663         127.461  \n",
       "...                                   ...             ...  \n",
       "1498                             0.052849         110.264  \n",
       "1499                             0.052849         109.254  \n",
       "1500                             0.052849         106.604  \n",
       "1501                             0.052849         106.224  \n",
       "1502                             0.052849         104.204  \n",
       "\n",
       "[1503 rows x 6 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airfoilDataset = pd.read_csv(\"airfoil_self_noise.dat\", sep=\"\\t\", names=['Frequency', 'Angle of attack', 'Chord length', 'Free-stream velocity', 'Suction side displacement thickness', 'Pressure level'])\n",
    "airfoilDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardScaler:\n",
    "\n",
    "    def __init__(self, mean=None, std=None, epsilon=1e-7):\n",
    "        \"\"\"Standard Scaler.\n",
    "        The class can be used to normalize PyTorch Tensors using native functions. The module does not expect the\n",
    "        tensors to be of any specific shape; as long as the features are the last dimension in the tensor, the module\n",
    "        will work fine.\n",
    "        :param mean: The mean of the features. The property will be set after a call to fit.\n",
    "        :param std: The standard deviation of the features. The property will be set after a call to fit.\n",
    "        :param epsilon: Used to avoid a Division-By-Zero exception.\n",
    "        \"\"\"\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def fit(self, values):\n",
    "        dims = list(range(values.dim() - 1))\n",
    "        self.mean = torch.mean(values, dim=dims)\n",
    "        self.std = torch.std(values, dim=dims)\n",
    "\n",
    "    def transform(self, values):\n",
    "        return (values - self.mean) / (self.std + self.epsilon)\n",
    "\n",
    "    def fit_transform(self, values):\n",
    "        self.fit(values)\n",
    "        return self.transform(values)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"mean: {self.mean}, std:{self.std}, epsilon:{self.epsilon}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset y Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AirfoilDataset(Dataset):\n",
    "  def __init__(self, src_file, root_dir, transform=None):\n",
    "    airfoilDataset = pd.read_csv(\"airfoil_self_noise.dat\", sep=\"\\t\", names=['Frequency', 'Angle of attack', 'Chord length', 'Free-stream velocity', 'Suction side displacement thickness', 'Pressure level'])\n",
    "    X = airfoilDataset.loc[:, ~airfoilDataset.columns.isin(['Pressure level'])]\n",
    "    Y = airfoilDataset[[\"Pressure level\"]]\n",
    "\n",
    "    x1=X.iloc[:,0:5].values\n",
    "    x_tensor = torch.tensor(x1)\n",
    "\n",
    "    y_tensor = torch.tensor(Y.values).type(torch.float32)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    XScalada = scaler.fit_transform(x_tensor).type(torch.float32)\n",
    "\n",
    "    self.data = torch.cat((XScalada,y_tensor),1)\n",
    "    self.root_dir = root_dir\n",
    "    self.transform = transform\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    if torch.is_tensor(idx):\n",
    "      idx = idx.tolist()\n",
    "\n",
    "    preds = self.data[idx, 0:5]\n",
    "    spcs = self.data[idx, 5]\n",
    "    sample = (preds, spcs)\n",
    "    \n",
    "    if self.transform:\n",
    "      sample = self.transform(sample)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.6618, -1.1460,  1.7987,  1.3125, -0.6446]), tensor(126.2010))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "airfoilDataset = AirfoilDataset(\"airfoil_self_noise.dat\",\".\")\n",
    "display(airfoilDataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# División en train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tam dataset: 1503 train: 1202 tamVal: 301\n"
     ]
    }
   ],
   "source": [
    "lonxitudeDataset = len(airfoilDataset)\n",
    "\n",
    "tamTrain =int(lonxitudeDataset*0.8)\n",
    "tamVal = lonxitudeDataset - tamTrain\n",
    "\n",
    "print(f\"Tam dataset: {lonxitudeDataset} train: {tamTrain} tamVal: {tamVal}\")\n",
    "train_set, val_set = random_split(airfoilDataset,[tamTrain,tamVal])\n",
    "train_ldr = torch.utils.data.DataLoader(train_set, batch_size=2,\n",
    "    shuffle=True, drop_last=False)\n",
    "validation_loader =torch.utils.data.DataLoader(val_set, batch_size=4, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, entradas):\n",
    "        super(Model, self).__init__()\n",
    "        self.layer1 = nn.Linear(entradas, 100)\n",
    "        self.layer2 = nn.Linear(100, 50)\n",
    "        self.layer3 = nn.Linear(in_features=50, out_features=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = F.relu(self.layer3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instanciación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (layer1): Linear(in_features=5, out_features=100, bias=True)\n",
       "  (layer2): Linear(in_features=100, out_features=50, bias=True)\n",
       "  (layer3): Linear(in_features=50, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model     = Model(5)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_fn   = nn.MSELoss(reduction='sum')\n",
    "display(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrada:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6220, -1.1460,  0.1695, -1.2304, -0.6879],\n",
       "        [-0.5984,  0.3578, -0.3736, -0.7231,  0.1004]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desexada:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([117.9570, 129.5800])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saída:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0146],\n",
       "        [0.0000]], grad_fn=<ReluBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor(61402.4414, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entradaProba,dest = next(iter(train_ldr))\n",
    "\n",
    "print(\"Entrada:\")\n",
    "display(entradaProba)\n",
    "\n",
    "print(\"Desexada:\")\n",
    "display(dest)\n",
    "\n",
    "saida = model(entradaProba) # esta é a proba de verdade\n",
    "print(\"Saída:\")\n",
    "display(saida)\n",
    "\n",
    "loss_fn(saida, dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Función de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    for i, data in enumerate(train_ldr):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    return running_loss / len(train_ldr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "writer = None\n",
    "tb = SummaryWriter()\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch, tb)\n",
    "\n",
    "    mean_squared_error = MeanSquaredError()\n",
    "    mean_absolute_error = MeanAbsoluteError()\n",
    "    r2Score = R2Score()\n",
    "    model.train(False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for entradas, saidas in validation_loader:\n",
    "            voutputs = model(entradas).flatten()\n",
    "            mean_squared_error(voutputs,saidas)\n",
    "            mean_absolute_error(voutputs,saidas)\n",
    "            r2Score(voutputs,saidas)\n",
    "\n",
    "    errorMedio = mean_squared_error.compute()\n",
    "    errorAbsolute =mean_absolute_error.compute()\n",
    "    r2 = r2Score.compute()\n",
    "\n",
    "    tb.add_scalar('Average loss airfoil', avg_loss, epoch)\n",
    "    tb.add_scalar('Mean squared error airfoil', errorMedio, epoch)\n",
    "    tb.add_scalar('Mean absolute error airfoil', errorAbsolute, epoch)\n",
    "    tb.add_scalar('R2Score airfoil', r2, epoch)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_tensorboard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
